{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6b8iokaj1Xy"
      },
      "source": [
        "## üì¶ Setup & GitHub Repo Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBd-KIAFj1X1",
        "outputId": "445ac21c-a19b-4b4e-9752-4383722bfa7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Real-time-competitor-strategy-tracker'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Counting objects: 100% (169/169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 169 (delta 44), reused 161 (delta 38), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (169/169), 7.10 MiB | 10.76 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n",
            "total 40892\n",
            "drwxr-xr-x 11 root root     4096 Oct 16 15:07 .\n",
            "drwxr-xr-x  1 root root     4096 Oct 16 15:07 ..\n",
            "-rw-r--r--  1 root root 14528512 Oct 16 15:07 competitor_tracker.db\n",
            "drwxr-xr-x  2 root root     4096 Oct 16 15:07 database\n",
            "drwxr-xr-x  2 root root     4096 Oct 16 15:07 data_collection\n",
            "-rw-r--r--  1 root root      870 Oct 16 15:07 DATACOLLECTIONREADME.md\n",
            "drwxr-xr-x  2 root root     4096 Oct 16 15:07 docs\n",
            "-rw-r--r--  1 root root      621 Oct 16 15:07 eslint.config.js\n",
            "drwxr-xr-x  2 root root     4096 Oct 16 15:07 exports\n",
            "drwxr-xr-x  8 root root     4096 Oct 16 15:07 .git\n",
            "-rw-r--r--  1 root root     5011 Oct 16 15:07 .gitignore\n",
            "-rw-r--r--  1 root root      361 Oct 16 15:07 index.html\n",
            "-rw-r--r--  1 root root        0 Oct 16 15:07 iphone.db\n",
            "drwxr-xr-x  2 root root     4096 Oct 16 15:07 notebooks\n",
            "-rw-r--r--  1 root root     1306 Oct 16 15:07 package.json\n",
            "-rw-r--r--  1 root root   174551 Oct 16 15:07 package-lock.json\n",
            "drwxr-xr-x  3 root root     4096 Oct 16 15:07 public\n",
            "-rw-r--r--  1 root root 13422531 Oct 16 15:07 raw_scrapes_export.csv\n",
            "-rw-r--r--  1 root root 13652961 Oct 16 15:07 raw_scrapes_export.json\n",
            "-rw-r--r--  1 root root     2694 Oct 16 15:07 README.md\n",
            "drwxr-xr-x  2 root root     4096 Oct 16 15:07 requirements.txt\n",
            "drwxr-xr-x  9 root root     4096 Oct 16 15:07 src\n",
            "-rw-r--r--  1 root root      703 Oct 16 15:07 tsconfig.app.json\n",
            "-rw-r--r--  1 root root      119 Oct 16 15:07 tsconfig.json\n",
            "-rw-r--r--  1 root root      606 Oct 16 15:07 tsconfig.node.json\n",
            "-rw-r--r--  1 root root      224 Oct 16 15:07 vite.config.ts\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Techierookies/Real-time-competitor-strategy-tracker.git\n",
        "!cd Real-time-competitor-strategy-tracker && ls -la"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4NTqnaJKj1X8",
        "outputId": "f25194b7-9b37-4035-d48a-006a3127fbee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting faker\n",
            "  Downloading faker-37.11.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Downloading faker-37.11.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.11.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "‚úÖ All packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow keras numpy pandas scikit-learn faker transformers torch\n",
        "!pip install matplotlib seaborn plotly tabulate nltk textblob\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"‚úÖ All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVEYJwEqj1X-",
        "outputId": "46e1363d-015a-4560-b91b-fd7df867533c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "PyTorch version: 2.8.0+cu126\n",
            "‚úÖ Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import torch\n",
        "from faker import Faker\n",
        "import json\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from tabulate import tabulate\n",
        "import string\n",
        "import itertools\n",
        "from collections import defaultdict\n",
        "import shutil\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(\"‚úÖ Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh3Y2V56j1YA"
      },
      "source": [
        "## üîç Robust Database Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENi04MPKj1YD",
        "outputId": "c49793ad-564f-422a-f63b-71eb38f54482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Database file found: Real-time-competitor-strategy-tracker/competitor_tracker.db\n",
            "üìä File size: 14528512 bytes\n",
            "üìã Tables found: 2\n",
            "‚úÖ Available tables: ['raw_scrapes', 'sqlite_sequence']\n",
            "\n",
            "üìä Table 'raw_scrapes' columns: ['id', 'model', 'site', 'url', 'raw_html', 'scraped_at', 'price', 'rating', 'reviews']\n",
            "   Rows in table: 10\n",
            "\n",
            "‚úÖ Found iPhone models: ['iPhone 15', 'iPhone 16', 'iPhone 17']\n",
            "\n",
            "üí∞ Real Price Ranges:\n",
            "   iPhone 15: ‚Çπ71,197 - ‚Çπ148,357\n",
            "   iPhone 16: ‚Çπ74,869 - ‚Çπ129,933\n",
            "   iPhone 17: ‚Çπ85,408 - ‚Çπ144,713\n",
            "\n",
            "‚≠ê Real Rating Ranges:\n",
            "   iPhone 15: 3.5 - 4.9\n",
            "   iPhone 16: 4.1 - 4.4\n",
            "   iPhone 17: 3.7 - 4.1\n",
            "\n",
            "üéØ Final iPhone models: ['iPhone 15', 'iPhone 16', 'iPhone 17']\n",
            "‚úÖ Database analysis complete!\n"
          ]
        }
      ],
      "source": [
        "db_path = 'Real-time-competitor-strategy-tracker/competitor_tracker.db'\n",
        "\n",
        "if not os.path.exists(db_path):\n",
        "    print(f\"‚ùå Database file not found at: {db_path}\")\n",
        "    IPHONE_MODELS = ['iPhone 15', 'iPhone 16', 'iPhone 17']\n",
        "    PRICE_RANGES = {\n",
        "        'iPhone 15': (70835, 93640),\n",
        "        'iPhone 16': (127494, 148357),\n",
        "        'iPhone 17': (145000, 180000)\n",
        "    }\n",
        "    RATING_RANGES = {\n",
        "        'iPhone 15': (4.3, 4.9),\n",
        "        'iPhone 16': (4.1, 4.5),\n",
        "        'iPhone 17': (4.5, 5.0)\n",
        "    }\n",
        "else:\n",
        "    file_size = os.path.getsize(db_path)\n",
        "    print(f\"üìÅ Database file found: {db_path}\")\n",
        "    print(f\"üìä File size: {file_size} bytes\")\n",
        "\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_path)\n",
        "        tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
        "        tables_df = pd.read_sql_query(tables_query, conn)\n",
        "\n",
        "        print(f\"üìã Tables found: {len(tables_df)}\")\n",
        "\n",
        "        if len(tables_df) > 0:\n",
        "            print(f\"‚úÖ Available tables: {tables_df['name'].tolist()}\")\n",
        "\n",
        "            iphone_models = set()\n",
        "            real_price_ranges = {}\n",
        "            real_rating_ranges = {}\n",
        "\n",
        "            for table_name in tables_df['name']:\n",
        "                try:\n",
        "                    schema_query = f\"PRAGMA table_info({table_name});\"\n",
        "                    schema = pd.read_sql_query(schema_query, conn)\n",
        "                    print(f\"\\nüìä Table '{table_name}' columns: {schema['name'].tolist()}\")\n",
        "\n",
        "                    data_query = f\"SELECT * FROM {table_name} LIMIT 10;\"\n",
        "                    data = pd.read_sql_query(data_query, conn)\n",
        "                    print(f\"   Rows in table: {len(data)}\")\n",
        "\n",
        "                    if 'model' in data.columns and 'price' in data.columns and 'rating' in data.columns:\n",
        "                        for _, row in data.iterrows():\n",
        "                            model_str = str(row['model'])\n",
        "                            if 'iPhone' in model_str:\n",
        "                                for model_num in ['15', '16', '17']:\n",
        "                                    if model_num in model_str:\n",
        "                                        model_name = f'iPhone {model_num}'\n",
        "                                        iphone_models.add(model_name)\n",
        "\n",
        "                                        try:\n",
        "                                            price_val = float(str(row['price']).replace('‚Çπ', '').replace(',', ''))\n",
        "                                            rating_val = float(row['rating'])\n",
        "\n",
        "                                            if model_name not in real_price_ranges:\n",
        "                                                real_price_ranges[model_name] = [price_val, price_val]\n",
        "                                                real_rating_ranges[model_name] = [rating_val, rating_val]\n",
        "                                            else:\n",
        "                                                real_price_ranges[model_name][0] = min(real_price_ranges[model_name][0], price_val)\n",
        "                                                real_price_ranges[model_name][1] = max(real_price_ranges[model_name][1], price_val)\n",
        "                                                real_rating_ranges[model_name][0] = min(real_rating_ranges[model_name][0], rating_val)\n",
        "                                                real_rating_ranges[model_name][1] = max(real_rating_ranges[model_name][1], rating_val)\n",
        "                                        except:\n",
        "                                            pass\n",
        "                        break\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"   ‚ö†Ô∏è Error reading table '{table_name}': {e}\")\n",
        "\n",
        "            conn.close()\n",
        "\n",
        "            if iphone_models and real_price_ranges:\n",
        "                IPHONE_MODELS = sorted(list(iphone_models))\n",
        "                PRICE_RANGES = {model: tuple(ranges) for model, ranges in real_price_ranges.items()}\n",
        "                RATING_RANGES = {model: tuple(ranges) for model, ranges in real_rating_ranges.items()}\n",
        "\n",
        "                print(f\"\\n‚úÖ Found iPhone models: {IPHONE_MODELS}\")\n",
        "                print(f\"\\nüí∞ Real Price Ranges:\")\n",
        "                for model, (min_p, max_p) in PRICE_RANGES.items():\n",
        "                    print(f\"   {model}: ‚Çπ{min_p:,.0f} - ‚Çπ{max_p:,.0f}\")\n",
        "                print(f\"\\n‚≠ê Real Rating Ranges:\")\n",
        "                for model, (min_r, max_r) in RATING_RANGES.items():\n",
        "                    print(f\"   {model}: {min_r:.1f} - {max_r:.1f}\")\n",
        "            else:\n",
        "                IPHONE_MODELS = ['iPhone 15', 'iPhone 16', 'iPhone 17']\n",
        "                PRICE_RANGES = {\n",
        "                    'iPhone 15': (70835, 93640),\n",
        "                    'iPhone 16': (127494, 148357),\n",
        "                    'iPhone 17': (145000, 180000)\n",
        "                }\n",
        "                RATING_RANGES = {\n",
        "                    'iPhone 15': (4.3, 4.9),\n",
        "                    'iPhone 16': (4.1, 4.5),\n",
        "                    'iPhone 17': (4.5, 5.0)\n",
        "                }\n",
        "        else:\n",
        "            IPHONE_MODELS = ['iPhone 15', 'iPhone 16', 'iPhone 17']\n",
        "            PRICE_RANGES = {\n",
        "                'iPhone 15': (70835, 93640),\n",
        "                'iPhone 16': (127494, 148357),\n",
        "                'iPhone 17': (145000, 180000)\n",
        "            }\n",
        "            RATING_RANGES = {\n",
        "                'iPhone 15': (4.3, 4.9),\n",
        "                'iPhone 16': (4.1, 4.5),\n",
        "                'iPhone 17': (4.5, 5.0)\n",
        "            }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error accessing database: {e}\")\n",
        "        IPHONE_MODELS = ['iPhone 15', 'iPhone 16', 'iPhone 17']\n",
        "        PRICE_RANGES = {\n",
        "            'iPhone 15': (70835, 93640),\n",
        "            'iPhone 16': (127494, 148357),\n",
        "            'iPhone 17': (145000, 180000)\n",
        "        }\n",
        "        RATING_RANGES = {\n",
        "            'iPhone 15': (4.3, 4.9),\n",
        "            'iPhone 16': (4.1, 4.5),\n",
        "            'iPhone 17': (4.5, 5.0)\n",
        "        }\n",
        "\n",
        "print(f\"\\nüéØ Final iPhone models: {IPHONE_MODELS}\")\n",
        "print(\"‚úÖ Database analysis complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT_uQ7Bkj1YH"
      },
      "source": [
        "## üéØ Enhanced Data Variation Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDSBVt_Fj1YK",
        "outputId": "5ef8dd12-2fcf-495c-b1d8-716492a1afb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Enhanced variation components initialized!\n",
            "üì± Models: ['iPhone 15', 'iPhone 16', 'iPhone 17']\n",
            "üè™ Sites: ['Amazon', 'Flipkart']\n",
            "üìù Review components: 18 adjectives\n",
            "üé≠ Review templates: 13 variations\n"
          ]
        }
      ],
      "source": [
        "fake = Faker(['en_US', 'en_IN', 'en_GB', 'en_AU'])\n",
        "Faker.seed(None)\n",
        "\n",
        "SITES = ['Amazon', 'Flipkart']\n",
        "SITE_WEIGHTS = [0.6, 0.4]\n",
        "\n",
        "def generate_realistic_price(model, base_ranges):\n",
        "    base_min, base_max = base_ranges.get(model, (70000, 180000))\n",
        "\n",
        "    market_factor = np.random.uniform(0.85, 1.15)\n",
        "    seasonal_factor = np.random.uniform(0.90, 1.10)\n",
        "    competition_factor = np.random.uniform(0.88, 1.12)\n",
        "\n",
        "    adjusted_min = base_min * market_factor * seasonal_factor * competition_factor\n",
        "    adjusted_max = base_max * market_factor * seasonal_factor * competition_factor\n",
        "\n",
        "    base_price = np.random.uniform(adjusted_min, adjusted_max)\n",
        "    price_noise = np.random.uniform(-500, 500)\n",
        "    final_price = base_price + price_noise\n",
        "\n",
        "    return max(base_min * 0.8, final_price)\n",
        "\n",
        "def generate_realistic_rating(model, base_ranges):\n",
        "    base_min, base_max = base_ranges.get(model, (4.0, 5.0))\n",
        "\n",
        "    alpha, beta_param = 5, 2\n",
        "    rating_factor = np.random.beta(alpha, beta_param)\n",
        "\n",
        "    rating = base_min + (base_max - base_min) * rating_factor\n",
        "    rating_noise = np.random.uniform(-0.05, 0.05)\n",
        "    final_rating = rating + rating_noise\n",
        "\n",
        "    return round(max(3.0, min(5.0, final_rating)), 1)\n",
        "\n",
        "REVIEW_COMPONENTS = {\n",
        "    'positive_adjectives': [\n",
        "        'excellent', 'outstanding', 'amazing', 'fantastic', 'superb', 'brilliant',\n",
        "        'incredible', 'remarkable', 'exceptional', 'wonderful', 'impressive',\n",
        "        'great', 'good', 'nice', 'solid', 'decent', 'satisfying', 'reliable'\n",
        "    ],\n",
        "    'features': [\n",
        "        'camera quality', 'battery life', 'performance', 'display', 'design',\n",
        "        'build quality', 'user interface', 'speed', 'storage', 'connectivity',\n",
        "        'sound quality', 'screen clarity', 'overall experience', 'functionality',\n",
        "        'features', 'capabilities', 'responsiveness', 'durability'\n",
        "    ],\n",
        "    'contexts': [\n",
        "        'daily use', 'gaming', 'photography', 'work', 'entertainment',\n",
        "        'professional tasks', 'multimedia', 'social media', 'business',\n",
        "        'personal use', 'family use', 'travel', 'outdoor activities'\n",
        "    ],\n",
        "    'sentiments': {\n",
        "        'very_positive': [\n",
        "            'Perfect for {context}.', 'Absolutely love the {feature}.',\n",
        "            'Highly recommend for {context}.', '{adjective} {feature}.',\n",
        "            'Best phone for {context}.', 'Incredible {feature} quality.'\n",
        "        ],\n",
        "        'positive': [\n",
        "            'Great {feature} and good for {context}.',\n",
        "            'Good phone with {adjective} {feature}.',\n",
        "            'Satisfied with the {feature}.',\n",
        "            'Nice {feature}, works well for {context}.'\n",
        "        ],\n",
        "        'mixed': [\n",
        "            'Good {feature} but {negative_aspect} could be better.',\n",
        "            '{adjective} phone overall, though {negative_aspect} is average.',\n",
        "            'Decent for {context}, {feature} is good.'\n",
        "        ]\n",
        "    },\n",
        "    'negative_aspects': [\n",
        "        'battery life', 'price point', 'storage capacity', 'camera in low light',\n",
        "        'charging speed', 'weight', 'size', 'software updates',\n",
        "        'heat management', 'signal strength'\n",
        "    ]\n",
        "}\n",
        "\n",
        "def generate_unique_review(model, rating):\n",
        "    if rating >= 4.5:\n",
        "        sentiment_type = 'very_positive'\n",
        "    elif rating >= 4.0:\n",
        "        sentiment_type = 'positive'\n",
        "    else:\n",
        "        sentiment_type = 'mixed'\n",
        "\n",
        "    template = np.random.choice(REVIEW_COMPONENTS['sentiments'][sentiment_type])\n",
        "    adjective = np.random.choice(REVIEW_COMPONENTS['positive_adjectives'])\n",
        "    feature = np.random.choice(REVIEW_COMPONENTS['features'])\n",
        "    context = np.random.choice(REVIEW_COMPONENTS['contexts'])\n",
        "    negative_aspect = np.random.choice(REVIEW_COMPONENTS['negative_aspects'])\n",
        "\n",
        "    review = template.format(\n",
        "        adjective=adjective,\n",
        "        feature=feature,\n",
        "        context=context,\n",
        "        negative_aspect=negative_aspect\n",
        "    )\n",
        "\n",
        "    return review\n",
        "\n",
        "print(\"üéØ Enhanced variation components initialized!\")\n",
        "print(f\"üì± Models: {IPHONE_MODELS}\")\n",
        "print(f\"üè™ Sites: {SITES}\")\n",
        "print(f\"üìù Review components: {len(REVIEW_COMPONENTS['positive_adjectives'])} adjectives\")\n",
        "print(f\"üé≠ Review templates: {sum(len(v) for v in REVIEW_COMPONENTS['sentiments'].values())} variations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZStDuR8j1YU"
      },
      "source": [
        "## üïí Generate Dataset with Timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EBRpmxWj1YV",
        "outputId": "8f7d2af2-d451-4a55-edac-f99346673748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Starting timestamped dataset generation...\n",
            "üìä Generating 2500 diverse records with timestamps...\n",
            "üìÖ Time range: 2025-04-19 to 2025-10-16\n",
            "   Generated 500/2500 records with timestamps...\n",
            "   Generated 1000/2500 records with timestamps...\n",
            "   Generated 1500/2500 records with timestamps...\n",
            "   Generated 2000/2500 records with timestamps...\n",
            "   Generated 2500/2500 records with timestamps...\n",
            "\n",
            "‚úÖ Timestamped dataset generated successfully!\n",
            "   Total records: 2500\n",
            "   Columns: ['ID', 'Model', 'Source', 'Price', 'Rating', 'Reviews', 'URL', 'Scraped_At']\n",
            "   Date range: 2025-04-19 16:15:07 to 2025-10-16 08:55:07\n",
            "   Models: ['iPhone 15' 'iPhone 16' 'iPhone 17']\n",
            "   Sources: [np.str_('Amazon') np.str_('Flipkart')]\n",
            "   Unique prices: 2500 / 2500 (100.0%)\n",
            "   Unique ratings: 16 / 2500 (0.6%)\n",
            "   Unique reviews: 1047 / 2500 (41.9%)\n",
            "   Unique URLs: 2500 / 2500 (100.0%)\n",
            "   Unique timestamps: 2488 / 2500 (99.5%)\n"
          ]
        }
      ],
      "source": [
        "def generate_unique_url(site, model, used_urls):\n",
        "    max_attempts = 100\n",
        "    attempt = 0\n",
        "\n",
        "    while attempt < max_attempts:\n",
        "        if site == 'Amazon':\n",
        "            patterns = [\n",
        "                f\"https://www.amazon.in/dp/{fake.bothify('??########')}\",\n",
        "                f\"https://www.amazon.in/Apple-{model.replace(' ', '-')}/dp/{fake.bothify('??########')}\",\n",
        "                f\"https://www.amazon.in/gp/product/{fake.bothify('??########')}\"\n",
        "            ]\n",
        "            url = np.random.choice(patterns)\n",
        "        else:\n",
        "            model_slug = model.lower().replace(' ', '-')\n",
        "            patterns = [\n",
        "                f\"https://www.flipkart.com/apple-{model_slug}/p/{fake.bothify('itm????????')}\",\n",
        "                f\"https://www.flipkart.com/{model_slug}/p/{fake.bothify('itm????????')}\",\n",
        "                f\"https://www.flipkart.com/apple-{model_slug}-smartphone/p/{fake.bothify('itm????????')}\"\n",
        "            ]\n",
        "            url = np.random.choice(patterns)\n",
        "\n",
        "        if url not in used_urls:\n",
        "            used_urls.add(url)\n",
        "            return url\n",
        "\n",
        "        attempt += 1\n",
        "\n",
        "    timestamp = str(int(datetime.now().timestamp() * 1000000))[-8:]\n",
        "    if site == 'Amazon':\n",
        "        url = f\"https://www.amazon.in/dp/{fake.bothify('??')}{timestamp}\"\n",
        "    else:\n",
        "        url = f\"https://www.flipkart.com/apple-{model.lower().replace(' ', '-')}/p/itm{timestamp}\"\n",
        "\n",
        "    used_urls.add(url)\n",
        "    return url\n",
        "\n",
        "def generate_diverse_records_with_datetime(target_records=2500):\n",
        "    records = []\n",
        "    used_urls = set()\n",
        "    used_combinations = set()\n",
        "    price_history = defaultdict(list)\n",
        "    rating_history = defaultdict(list)\n",
        "\n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=180)\n",
        "\n",
        "    print(f\"üìä Generating {target_records} diverse records with timestamps...\")\n",
        "    print(f\"üìÖ Time range: {start_date.date()} to {end_date.date()}\")\n",
        "\n",
        "    for i in range(target_records):\n",
        "        max_attempts = 50\n",
        "        attempt = 0\n",
        "\n",
        "        while attempt < max_attempts:\n",
        "            variation_seed = i * 13 + attempt * 7\n",
        "            np.random.seed(variation_seed)\n",
        "\n",
        "            if i < target_records // 3:\n",
        "                model = IPHONE_MODELS[i % len(IPHONE_MODELS)]\n",
        "            else:\n",
        "                model_weights = [1.0] * len(IPHONE_MODELS)\n",
        "                for idx, m in enumerate(IPHONE_MODELS):\n",
        "                    model_count = sum(1 for r in records if r.get('Model') == m)\n",
        "                    if model_count > target_records // len(IPHONE_MODELS):\n",
        "                        model_weights[idx] *= 0.5\n",
        "\n",
        "                model_weights = np.array(model_weights)\n",
        "                model_weights /= model_weights.sum()\n",
        "                model = np.random.choice(IPHONE_MODELS, p=model_weights)\n",
        "\n",
        "            site_counts = {'Amazon': 0, 'Flipkart': 0}\n",
        "            for r in records:\n",
        "                site_counts[r.get('Source', 'Amazon')] += 1\n",
        "\n",
        "            if site_counts['Amazon'] > site_counts['Flipkart'] + 50:\n",
        "                site = 'Flipkart'\n",
        "            elif site_counts['Flipkart'] > site_counts['Amazon'] + 50:\n",
        "                site = 'Amazon'\n",
        "            else:\n",
        "                site = np.random.choice(SITES, p=SITE_WEIGHTS)\n",
        "\n",
        "            # Generate realistic timestamp\n",
        "            days_back = np.random.randint(0, 180)\n",
        "            hours_back = np.random.randint(0, 24)\n",
        "            minutes_back = np.random.randint(0, 60)\n",
        "            scraped_at = end_date - timedelta(days=days_back, hours=hours_back, minutes=minutes_back)\n",
        "\n",
        "            # Time-based price variations\n",
        "            base_price = generate_realistic_price(model, PRICE_RANGES)\n",
        "\n",
        "            if days_back > 120:\n",
        "                time_factor = np.random.uniform(0.92, 1.08)\n",
        "            elif days_back > 60:\n",
        "                time_factor = np.random.uniform(0.96, 1.04)\n",
        "            else:\n",
        "                time_factor = np.random.uniform(0.98, 1.02)\n",
        "\n",
        "            price = base_price * time_factor\n",
        "\n",
        "            # Seasonal pricing effects\n",
        "            month = scraped_at.month\n",
        "            if month in [11, 12]:\n",
        "                price *= np.random.uniform(0.85, 0.95)\n",
        "            elif month in [1, 2]:\n",
        "                price *= np.random.uniform(1.02, 1.08)\n",
        "            elif month in [9, 10]:\n",
        "                if model == 'iPhone 17':\n",
        "                    price *= np.random.uniform(1.05, 1.15)\n",
        "                else:\n",
        "                    price *= np.random.uniform(0.88, 0.95)\n",
        "\n",
        "            # Historical price awareness\n",
        "            model_prices = price_history[model]\n",
        "            if model_prices:\n",
        "                min_diff = min(abs(price - existing) for existing in model_prices)\n",
        "                if min_diff < 1000 and len(model_prices) > 10:\n",
        "                    price_adjustment = np.random.choice([-1, 1]) * np.random.uniform(1000, 5000)\n",
        "                    price += price_adjustment\n",
        "\n",
        "            rating = generate_realistic_rating(model, RATING_RANGES)\n",
        "\n",
        "            model_ratings = rating_history[model]\n",
        "            if model_ratings and rating in model_ratings[-20:]:\n",
        "                rating_adjustment = np.random.choice([-0.1, -0.2, 0.1, 0.2])\n",
        "                rating = max(3.0, min(5.0, rating + rating_adjustment))\n",
        "                rating = round(rating, 1)\n",
        "\n",
        "            combo_key = (model, site, int(price/1000), rating)\n",
        "\n",
        "            if combo_key not in used_combinations or attempt > 30:\n",
        "                used_combinations.add(combo_key)\n",
        "                break\n",
        "\n",
        "            attempt += 1\n",
        "\n",
        "        review = generate_unique_review(model, rating)\n",
        "        url = generate_unique_url(site, model, used_urls)\n",
        "\n",
        "        record = {\n",
        "            'ID': i + 1,\n",
        "            'Model': model,\n",
        "            'Source': site,\n",
        "            'Price': round(price, 2),\n",
        "            'Rating': rating,\n",
        "            'Reviews': review,\n",
        "            'URL': url,\n",
        "            'Scraped_At': scraped_at.strftime('%Y-%m-%d %H:%M:%S')\n",
        "        }\n",
        "\n",
        "        records.append(record)\n",
        "        price_history[model].append(price)\n",
        "        rating_history[model].append(rating)\n",
        "\n",
        "        if (i + 1) % 500 == 0:\n",
        "            print(f\"   Generated {i + 1}/{target_records} records with timestamps...\")\n",
        "\n",
        "    np.random.seed(42)\n",
        "    return records\n",
        "\n",
        "# Generate timestamped dataset\n",
        "print(\"üîÑ Starting timestamped dataset generation...\")\n",
        "diverse_records = generate_diverse_records_with_datetime(target_records=2500)\n",
        "\n",
        "df_diverse = pd.DataFrame(diverse_records)\n",
        "\n",
        "print(f\"\\n‚úÖ Timestamped dataset generated successfully!\")\n",
        "print(f\"   Total records: {len(df_diverse)}\")\n",
        "print(f\"   Columns: {list(df_diverse.columns)}\")\n",
        "print(f\"   Date range: {df_diverse['Scraped_At'].min()} to {df_diverse['Scraped_At'].max()}\")\n",
        "print(f\"   Models: {df_diverse['Model'].unique()}\")\n",
        "print(f\"   Sources: {df_diverse['Source'].unique()}\")\n",
        "print(f\"   Unique prices: {df_diverse['Price'].nunique()} / {len(df_diverse)} ({df_diverse['Price'].nunique()/len(df_diverse)*100:.1f}%)\")\n",
        "print(f\"   Unique ratings: {df_diverse['Rating'].nunique()} / {len(df_diverse)} ({df_diverse['Rating'].nunique()/len(df_diverse)*100:.1f}%)\")\n",
        "print(f\"   Unique reviews: {df_diverse['Reviews'].nunique()} / {len(df_diverse)} ({df_diverse['Reviews'].nunique()/len(df_diverse)*100:.1f}%)\")\n",
        "print(f\"   Unique URLs: {df_diverse['URL'].nunique()} / {len(df_diverse)} ({df_diverse['URL'].nunique()/len(df_diverse)*100:.1f}%)\")\n",
        "print(f\"   Unique timestamps: {df_diverse['Scraped_At'].nunique()} / {len(df_diverse)} ({df_diverse['Scraped_At'].nunique()/len(df_diverse)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thEVaIDvj1YZ"
      },
      "source": [
        "## üíæ Dataset Analysis & Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPXZkQhHj1Yb",
        "outputId": "572a18fb-075c-44d9-dbf1-876a9efe8e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Timestamped dataset saved as 'enhanced_synthetic_dataset_with_timestamps.csv'\n",
            "\n",
            "=== TIMESTAMPED DATASET STRUCTURE ===\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2500 entries, 0 to 2499\n",
            "Data columns (total 8 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   ID          2500 non-null   int64  \n",
            " 1   Model       2500 non-null   object \n",
            " 2   Source      2500 non-null   object \n",
            " 3   Price       2500 non-null   float64\n",
            " 4   Rating      2500 non-null   float64\n",
            " 5   Reviews     2500 non-null   object \n",
            " 6   URL         2500 non-null   object \n",
            " 7   Scraped_At  2500 non-null   object \n",
            "dtypes: float64(2), int64(1), object(5)\n",
            "memory usage: 156.4+ KB\n",
            "None\n",
            "\n",
            "Total Rows: 2500\n",
            "Total Columns: 8\n",
            "\n",
            "=== TIME RANGE ANALYSIS ===\n",
            "Earliest record: 2025-04-19 16:15:07\n",
            "Latest record: 2025-10-16 08:55:07\n",
            "Date span: 179 days\n",
            "\n",
            "=== FIRST 10 TIMESTAMPED RECORDS ===\n",
            "+------+-----------+----------+----------+----------+----------------------------------------------------+--------------------------------------------------------+---------------------+\n",
            "|   ID | Model     | Source   |    Price |   Rating | Reviews                                            | URL                                                    | Scraped_At          |\n",
            "|------+-----------+----------+----------+----------+----------------------------------------------------+--------------------------------------------------------+---------------------|\n",
            "|    1 | iPhone 15 | Amazon   | 118428   |      4.8 | Absolutely love the storage.                       | https://www.amazon.in/dp/yg74010297                    | 2025-06-21 15:05:07 |\n",
            "|    2 | iPhone 16 | Flipkart | 132321   |      4.4 | Nice screen clarity, works well for gaming.        | https://www.flipkart.com/apple-iphone-16/p/itmdoQfrRoO | 2025-08-02 22:30:07 |\n",
            "|    3 | iPhone 17 | Amazon   |  94609.4 |      4.1 | Nice overall experience, works well for daily use. | https://www.amazon.in/dp/us77719660                    | 2025-10-09 23:07:07 |\n",
            "|    4 | iPhone 15 | Amazon   |  97246.6 |      4.4 | Good phone with incredible build quality.          | https://www.amazon.in/dp/Lp85891897                    | 2025-09-05 14:48:07 |\n",
            "|    5 | iPhone 16 | Flipkart |  94431.9 |      4.6 | Best phone for multimedia.                         | https://www.flipkart.com/apple-iphone-16/p/itmPEasLlzL | 2025-10-05 01:45:07 |\n",
            "|    6 | iPhone 17 | Amazon   | 122880   |      4.2 | Great design and good for travel.                  | https://www.amazon.in/gp/product/Xd24536062            | 2025-08-14 06:47:07 |\n",
            "|    7 | iPhone 15 | Amazon   | 162380   |      3.9 | Decent for social media, functionality is good.    | https://www.amazon.in/Apple-iPhone-15/dp/LL92881900    | 2025-05-18 06:27:07 |\n",
            "|    8 | iPhone 16 | Amazon   | 116862   |      4.3 | Satisfied with the durability.                     | https://www.amazon.in/gp/product/XR30419935            | 2025-07-01 20:39:07 |\n",
            "|    9 | iPhone 17 | Amazon   | 138091   |      4   | Nice build quality, works well for photography.    | https://www.amazon.in/gp/product/ha31866162            | 2025-05-27 08:44:07 |\n",
            "|   10 | iPhone 15 | Amazon   | 109875   |      4.5 | Highly recommend for daily use.                    | https://www.amazon.in/Apple-iPhone-15/dp/xh11115886    | 2025-07-27 21:45:07 |\n",
            "+------+-----------+----------+----------+----------+----------------------------------------------------+--------------------------------------------------------+---------------------+\n",
            "\n",
            "=== TIME-BASED MODEL DISTRIBUTION ===\n",
            "   iPhone 15: 922 records (36.9%)\n",
            "      Price: ‚Çπ107321 ¬± 27871 | Rating: 4.49 ¬± 0.29\n",
            "      Time span: 2025-04-20 to 2025-10-16\n",
            "   iPhone 17: 816 records (32.6%)\n",
            "      Price: ‚Çπ120533 ¬± 27731 | Rating: 3.98 ¬± 0.18\n",
            "      Time span: 2025-04-19 to 2025-10-16\n",
            "   iPhone 16: 762 records (30.5%)\n",
            "      Price: ‚Çπ101747 ¬± 24529 | Rating: 4.31 ¬± 0.18\n",
            "      Time span: 2025-04-19 to 2025-10-16\n",
            "\n",
            "=== MONTHLY TRENDS ===\n",
            "            Avg_Price  Record_Count  Avg_Rating\n",
            "Scraped_At                                     \n",
            "2025-04     111116.94           152        4.26\n",
            "2025-05     111042.89           458        4.29\n",
            "2025-06     108450.32           405        4.28\n",
            "2025-07     111569.84           413        4.26\n",
            "2025-08     110407.88           442        4.28\n",
            "2025-09     108992.49           429        4.26\n",
            "2025-10     107113.42           201        4.24\n",
            "\n",
            "üéâ TIMESTAMPED DATASET GENERATION COMPLETE!\n",
            "‚úÖ 2500+ timestamped records with 6-month historical span\n",
            "‚úÖ Seasonal pricing effects and time-based variations\n",
            "‚úÖ Ready for time-series analysis and forecasting!\n"
          ]
        }
      ],
      "source": [
        "# Save timestamped CSV\n",
        "df_diverse.to_csv('enhanced_synthetic_dataset_with_timestamps.csv', index=False)\n",
        "\n",
        "print(\"üíæ Timestamped dataset saved as 'enhanced_synthetic_dataset_with_timestamps.csv'\")\n",
        "print(\"\\n=== TIMESTAMPED DATASET STRUCTURE ===\")\n",
        "print(df_diverse.info())\n",
        "\n",
        "print(f\"\\nTotal Rows: {len(df_diverse)}\")\n",
        "print(f\"Total Columns: {len(df_diverse.columns)}\")\n",
        "\n",
        "print(\"\\n=== TIME RANGE ANALYSIS ===\")\n",
        "df_diverse['Scraped_At'] = pd.to_datetime(df_diverse['Scraped_At'])\n",
        "earliest = df_diverse['Scraped_At'].min()\n",
        "latest = df_diverse['Scraped_At'].max()\n",
        "date_span = (latest - earliest).days\n",
        "\n",
        "print(f\"Earliest record: {earliest}\")\n",
        "print(f\"Latest record: {latest}\")\n",
        "print(f\"Date span: {date_span} days\")\n",
        "\n",
        "print(\"\\n=== FIRST 10 TIMESTAMPED RECORDS ===\")\n",
        "print(tabulate(df_diverse.head(10), headers='keys', tablefmt='psql', showindex=False))\n",
        "\n",
        "print(\"\\n=== TIME-BASED MODEL DISTRIBUTION ===\")\n",
        "model_dist = df_diverse['Model'].value_counts()\n",
        "for model, count in model_dist.items():\n",
        "    percentage = (count / len(df_diverse)) * 100\n",
        "    model_data = df_diverse[df_diverse['Model'] == model]\n",
        "    avg_price = model_data['Price'].mean()\n",
        "    price_std = model_data['Price'].std()\n",
        "    avg_rating = model_data['Rating'].mean()\n",
        "    rating_std = model_data['Rating'].std()\n",
        "    earliest_model = model_data['Scraped_At'].min()\n",
        "    latest_model = model_data['Scraped_At'].max()\n",
        "    print(f\"   {model}: {count} records ({percentage:.1f}%)\")\n",
        "    print(f\"      Price: ‚Çπ{avg_price:.0f} ¬± {price_std:.0f} | Rating: {avg_rating:.2f} ¬± {rating_std:.2f}\")\n",
        "    print(f\"      Time span: {earliest_model.date()} to {latest_model.date()}\")\n",
        "\n",
        "print(\"\\n=== MONTHLY TRENDS ===\")\n",
        "monthly_stats = df_diverse.groupby(df_diverse['Scraped_At'].dt.to_period('M')).agg({\n",
        "    'Price': ['mean', 'count'],\n",
        "    'Rating': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "monthly_stats.columns = ['Avg_Price', 'Record_Count', 'Avg_Rating']\n",
        "print(monthly_stats)\n",
        "\n",
        "print(\"\\nüéâ TIMESTAMPED DATASET GENERATION COMPLETE!\")\n",
        "print(\"‚úÖ 2500+ timestamped records with 6-month historical span\")\n",
        "print(\"‚úÖ Seasonal pricing effects and time-based variations\")\n",
        "print(\"‚úÖ Ready for time-series analysis and forecasting!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1mGJUwdj1Ye"
      },
      "source": [
        "## üóÑÔ∏è SQLite Export with Timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmBe12Kvj1Yf",
        "outputId": "bfaf76d0-9816-4607-ba45-e75c4f647281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserting 2500 records with timestamps...\n",
            "   500/2500 records inserted...\n",
            "   1000/2500 records inserted...\n",
            "   1500/2500 records inserted...\n",
            "   2000/2500 records inserted...\n",
            "   2500/2500 records inserted...\n",
            "\n",
            "Inserted 2500 records with timestamps\n",
            "\n",
            "Database Statistics with Time Range:\n",
            "--------------------------------------------------------------------------------\n",
            "iPhone 15   :  922 records | Price: ‚Çπ107,321 | Rating: 4.49\n",
            "              Time range: 2025-04-20 01:43:07 to 2025-10-16 08:55:07\n",
            "iPhone 16   :  762 records | Price: ‚Çπ101,747 | Rating: 4.31\n",
            "              Time range: 2025-04-19 16:15:07 to 2025-10-16 07:42:07\n",
            "iPhone 17   :  816 records | Price: ‚Çπ120,533 | Rating: 3.98\n",
            "              Time range: 2025-04-19 19:37:07 to 2025-10-16 07:08:07\n",
            "\n",
            "Moved DB and CSV to repository: Real-time-competitor-strategy-tracker\n",
            "\n",
            "üóÑÔ∏è SQLite export with timestamps complete!\n"
          ]
        }
      ],
      "source": [
        "# Complete working cell: Convert timestamps and export to SQLite with move to repo\n",
        "\n",
        "import sqlite3\n",
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Ensure timestamps are plain strings\n",
        "df_diverse['Scraped_At'] = df_diverse['Scraped_At'].astype(str)\n",
        "\n",
        "# SQLite export\n",
        "db_filename = 'synthetic_competitor_tracker.db'\n",
        "conn = sqlite3.connect(db_filename)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS synthetic_competitor_data (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    model TEXT NOT NULL,\n",
        "    site TEXT NOT NULL,\n",
        "    url TEXT,\n",
        "    raw_html TEXT,\n",
        "    scraped_at TEXT NOT NULL,\n",
        "    price REAL NOT NULL,\n",
        "    rating REAL NOT NULL,\n",
        "    reviews TEXT\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Inserting {len(df_diverse)} records with timestamps...\")\n",
        "\n",
        "for idx, row in df_diverse.iterrows():\n",
        "    cursor.execute(\"\"\"\n",
        "        INSERT INTO synthetic_competitor_data\n",
        "        (model, site, url, raw_html, scraped_at, price, rating, reviews)\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
        "    \"\"\", (\n",
        "        row['Model'],\n",
        "        row['Source'],\n",
        "        row['URL'],\n",
        "        f'<synthetic>Generated on {datetime.now().strftime(\"%Y-%m-%d\")}</synthetic>',\n",
        "        row['Scraped_At'],\n",
        "        row['Price'],\n",
        "        row['Rating'],\n",
        "        row['Reviews']\n",
        "    ))\n",
        "    if (idx + 1) % 500 == 0:\n",
        "        print(f\"   {idx + 1}/{len(df_diverse)} records inserted...\")\n",
        "\n",
        "conn.commit()\n",
        "\n",
        "cursor.execute(\"SELECT COUNT(*) FROM synthetic_competitor_data\")\n",
        "record_count = cursor.fetchone()[0]\n",
        "print(f\"\\nInserted {record_count} records with timestamps\")\n",
        "\n",
        "# Summary statistics\n",
        "cursor.execute(\"\"\"\n",
        "    SELECT model, COUNT(*) as count, AVG(price) as avg_price, AVG(rating) as avg_rating,\n",
        "           MIN(scraped_at) as earliest, MAX(scraped_at) as latest\n",
        "    FROM synthetic_competitor_data\n",
        "    GROUP BY model\n",
        "\"\"\")\n",
        "print(\"\\nDatabase Statistics with Time Range:\")\n",
        "print(\"-\" * 80)\n",
        "for model, count, avg_price, avg_rating, earliest, latest in cursor.fetchall():\n",
        "    print(f\"{model:12s}: {count:4d} records | Price: ‚Çπ{avg_price:,.0f} | Rating: {avg_rating:.2f}\")\n",
        "    print(f\"              Time range: {earliest} to {latest}\")\n",
        "\n",
        "# Move database and CSV to repo\n",
        "conn.close()\n",
        "repo_path = 'Real-time-competitor-strategy-tracker'\n",
        "if os.path.exists(repo_path):\n",
        "    shutil.copy2(db_filename, repo_path)\n",
        "    shutil.copy2('enhanced_synthetic_dataset_with_timestamps.csv', repo_path)\n",
        "    print(f\"\\nMoved DB and CSV to repository: {repo_path}\")\n",
        "else:\n",
        "    print(f\"\\nRepository not found. Files saved in current directory.\")\n",
        "\n",
        "print(\"\\nüóÑÔ∏è SQLite export with timestamps complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Replace with your file name (must exist in the current working directory)\n",
        "filename = \"enhanced_synthetic_dataset_with_timestamps.csv\"\n",
        "\n",
        "# Download the file\n",
        "files.download(filename)"
      ],
      "metadata": {
        "id": "iKzhyj3glNBh",
        "outputId": "7b172840-f860-4f27-90d2-d192d43fbea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1ba62279-f824-4eb3-903e-df85e5d928f5\", \"enhanced_synthetic_dataset_with_timestamps.csv\", 363370)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6XIbS9sDlNix"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}